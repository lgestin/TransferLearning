{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de lancer ce notebook avec Spark en local sur 4 threads...\n",
    "SPARK_OPTS='--master=local[4]' jupyter notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.2.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.3 (default, Oct  6 2017 12:04:38)\n",
      "SparkSession available as 'spark'.\n",
      "<SparkContext master=local[*] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import os\n",
    "filename = os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py')\n",
    "exec(compile(open(filename, \"rb\").read(), filename, 'exec'))\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import des différents packages nécessaires\n",
    "# Traitement de données\n",
    "import string\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# PySpark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Tokenizer, CountVectorizerModel\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Une fonction pour charger ou creer un CountVectorizerModel\n",
    "\n",
    "train_cv = 1 # 1 for training / 0 to load the model\n",
    "cvModelPath = './Data/count-vectorizer-model'\n",
    "\n",
    "def loadData(data_ingestion):\n",
    "    if train_cv:\n",
    "        # we train cv...\n",
    "        cv_model = CountVectorizer(inputCol = 'words', outputCol = 'X')\n",
    "    else:\n",
    "        # we load cv ! \n",
    "        cv = CountVectorizerModel.load(cvModelPath)\n",
    "    \n",
    "    tokenizer = Tokenizer(inputCol = \"comment\", outputCol = \"words\")\n",
    "    \n",
    "    # Creation of an empty DataFrame\n",
    "    field1 = StructField('score',IntegerType(),True)\n",
    "    field2 = StructField('X',VectorUDT() ,True)\n",
    "    \n",
    "    fields = []\n",
    "    fields.append(field1)\n",
    "    fields.append(field2)\n",
    "    \n",
    "    schema = StructType(fields)\n",
    "    \n",
    "    X = spark.createDataFrame(sc.emptyRDD(), schema)\n",
    "    \n",
    "    # Ingestion par fichier\n",
    "    for filePath in data_ingestion:\n",
    "        file = sc.textFile(filePath)\n",
    "        data = file.map(lambda line: line.split(\"\\t\")).toDF()\n",
    "        data = data.withColumnRenamed('_1', 'score') \n",
    "        data = data.withColumn('score', data['score'].cast(IntegerType()))\n",
    "        data = data.withColumnRenamed('_2', 'comment')\n",
    "        \n",
    "        data = tokenizer.transform(data)\n",
    "        \n",
    "        if train_cv :\n",
    "            cv = cv_model.fit(data)\n",
    "            \n",
    "        data = cv.transform(data)\n",
    "        \n",
    "        X = X.union(data.select('score', 'X'))\n",
    "    \n",
    "    try : \n",
    "        shutil.rmtree(cvModelPath, ignore_errors = True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    cv.save(cvModelPath)\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|score|                   X|\n",
      "+-----+--------------------+\n",
      "|    5|(262144,[0,1,5,7,...|\n",
      "|    4|(262144,[4,14,15,...|\n",
      "|    1|(262144,[46,240,4...|\n",
      "|    4|(262144,[0,1,2,3,...|\n",
      "|    4|(262144,[3,24,39,...|\n",
      "|    5|(262144,[0,13,20,...|\n",
      "|    5|(262144,[0,11,90,...|\n",
      "|    4|(262144,[2,10,13,...|\n",
      "|    4|(262144,[0,1,7,13...|\n",
      "|    5|(262144,[0,1,6,19...|\n",
      "|    5|(262144,[0,19,48,...|\n",
      "|    5|(262144,[0,3,6,13...|\n",
      "|    5|(262144,[11,19,51...|\n",
      "|    4|(262144,[0,3,23,3...|\n",
      "|    5|(262144,[0,3,13,6...|\n",
      "|    1|(262144,[0,5,15,7...|\n",
      "|    5|(262144,[0,11,18,...|\n",
      "|    4|(262144,[0,1,5,7,...|\n",
      "|    4|(262144,[16,17,31...|\n",
      "|    5|(262144,[0,1,2,3,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_ingestion = ['./Data/balanced_stemmed_amazon_350k.txt']\n",
    "\n",
    "X = loadData(data_ingestion)\n",
    "X.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>(5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>(4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>(2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                                  X\n",
       "0      5  (5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...\n",
       "1      4  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2      1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3      4  (4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4      4  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "5      5  (2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "6      5  (2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "7      4  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "8      4  (1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
       "9      5  (1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pd = X.toPandas()\n",
    "X_pd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pd.to_csv(\"./Data/bagOfWords.csv\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>(113463,[0,1,7,8,9,12,13,24,33,43,65,70,73,81,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>(113463,[3,17,18,35,47,55,67,202,300,308,321,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(113463,[50,216,423,675,1467,3314,4467,5400,17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>(113463,[0,1,2,4,12,20,30,39,44,47,51,60,78,79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(113463,[4,23,45,194,281,462,566,593,696,1711]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(113463,[0,15,22,44,69,93,134,325,405,451,543,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                                  X\n",
       "0      5  (113463,[0,1,7,8,9,12,13,24,33,43,65,70,73,81,...\n",
       "1      4  (113463,[3,17,18,35,47,55,67,202,300,308,321,3...\n",
       "2      1  (113463,[50,216,423,675,1467,3314,4467,5400,17...\n",
       "3      4  (113463,[0,1,2,4,12,20,30,39,44,47,51,60,78,79...\n",
       "4      4  (113463,[4,23,45,194,281,462,566,593,696,1711]...\n",
       "5      5  (113463,[0,15,22,44,69,93,134,325,405,451,543,..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_from_pd = pd.read_csv(\"./Data/bagOfWords.csv\", sep = \"\\t\")\n",
    "X_from_pd.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'score', 'X'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_from_pd.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "Nous implémentons un NaiveBayes puis un random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "X1 = X.select('score', 'X').where( (X.score == 4) | (X.score == 5) )\n",
    "\n",
    "NB = NaiveBayes(smoothing = 1.0, modelType = \"multinomial\", labelCol = \"score\", featuresCol = \"X\")\n",
    "#model = NB.fit(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|score|                   X|\n",
      "+-----+--------------------+\n",
      "|    5|(113463,[0,1,7,8,...|\n",
      "|    4|(113463,[3,17,18,...|\n",
      "|    1|(113463,[50,216,4...|\n",
      "|    4|(113463,[0,1,2,4,...|\n",
      "|    4|(113463,[4,23,45,...|\n",
      "|    5|(113463,[0,15,22,...|\n",
      "|    5|(113463,[0,9,139,...|\n",
      "|    4|(113463,[2,12,15,...|\n",
      "|    4|(113463,[0,1,8,15...|\n",
      "|    5|(113463,[0,1,6,21...|\n",
      "|    5|(113463,[0,21,46,...|\n",
      "|    5|(113463,[0,4,6,15...|\n",
      "|    5|(113463,[9,21,58,...|\n",
      "|    4|(113463,[0,4,31,3...|\n",
      "|    5|(113463,[0,4,15,4...|\n",
      "|    1|(113463,[0,7,18,6...|\n",
      "|    5|(113463,[0,9,20,2...|\n",
      "|    4|(113463,[0,1,7,8,...|\n",
      "|    4|(113463,[13,19,27...|\n",
      "|    5|(113463,[0,1,2,4,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175000  -  175000\n",
      "+-----+--------------------+\n",
      "|score|                   X|\n",
      "+-----+--------------------+\n",
      "|    1|(262144,[0,1,5,7,...|\n",
      "|    1|(262144,[4,14,15,...|\n",
      "|    1|(262144,[0,1,2,3,...|\n",
      "|    1|(262144,[3,24,39,...|\n",
      "|    1|(262144,[0,13,20,...|\n",
      "|    1|(262144,[0,11,90,...|\n",
      "|    1|(262144,[2,10,13,...|\n",
      "|    1|(262144,[0,1,7,13...|\n",
      "|    1|(262144,[0,1,6,19...|\n",
      "|    1|(262144,[0,19,48,...|\n",
      "|    1|(262144,[0,3,6,13...|\n",
      "|    1|(262144,[11,19,51...|\n",
      "|    1|(262144,[0,3,23,3...|\n",
      "|    1|(262144,[0,3,13,6...|\n",
      "|    1|(262144,[0,11,18,...|\n",
      "|    1|(262144,[0,1,5,7,...|\n",
      "|    1|(262144,[16,17,31...|\n",
      "|    1|(262144,[0,1,2,3,...|\n",
      "|    1|(262144,[48,55,69...|\n",
      "|    1|(262144,[3,29,34,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "X2_1 = X.where((X.score == 4)|(X.score == 5)).withColumn('score', lit(1))\n",
    "X2_0 = X.where((X.score == 1)| (X.score == 2) | (X.score == 3)).withColumn('score', lit(0))\n",
    "\n",
    "print(X2_1.count(), ' - ', X2_0.count())\n",
    "\n",
    "X2 = X2_1.union(X2_0)\n",
    "X2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|score|                   X|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    1|(113463,[0,1,7,8,...|[-421.38956913796...|[0.00145588742341...|       1.0|\n",
      "|    1|(113463,[3,17,18,...|[-265.59445234650...|[0.81795169456594...|       0.0|\n",
      "|    1|(113463,[0,1,2,4,...|[-1093.5794889329...|[2.69468657757508...|       1.0|\n",
      "|    1|(113463,[4,23,45,...|[-81.546492754511...|[0.70894833793054...|       0.0|\n",
      "|    1|(113463,[0,15,22,...|[-183.16090056105...|[0.40769953415888...|       1.0|\n",
      "|    1|(113463,[0,9,139,...|[-87.038373058332...|[0.00214170430029...|       1.0|\n",
      "|    1|(113463,[2,12,15,...|[-111.98180698004...|[0.01561747942132...|       1.0|\n",
      "|    1|(113463,[0,1,8,15...|[-274.99054237735...|[3.76934719208345...|       1.0|\n",
      "|    1|(113463,[0,1,6,21...|[-164.37811017222...|[4.90553171319196...|       1.0|\n",
      "|    1|(113463,[0,21,46,...|[-106.93708400064...|[0.01252320023207...|       1.0|\n",
      "|    1|(113463,[0,4,6,15...|[-231.68216661992...|[1.60483486980395...|       1.0|\n",
      "|    1|(113463,[9,21,58,...|[-138.49322599138...|[7.77817835105874...|       1.0|\n",
      "|    1|(113463,[0,4,31,3...|[-206.77704429277...|[0.97166821093811...|       0.0|\n",
      "|    1|(113463,[0,4,15,4...|[-105.29681162743...|[0.04867918964810...|       1.0|\n",
      "|    1|(113463,[0,9,20,2...|[-191.22725612444...|[6.84828826449862...|       1.0|\n",
      "|    1|(113463,[0,1,7,8,...|[-320.53167736357...|[0.01568019831671...|       1.0|\n",
      "|    1|(113463,[13,19,27...|[-396.70381044226...|[0.00192176916059...|       1.0|\n",
      "|    1|(113463,[0,1,2,4,...|[-1067.1161906251...|[3.15673382095601...|       1.0|\n",
      "|    1|(113463,[46,61,71...|[-116.89549027868...|[0.99198897324053...|       0.0|\n",
      "|    1|(113463,[4,30,39,...|[-327.59368196224...|[9.48400209727753...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = NB.fit(X2)\n",
    "Y = model.transform(X2)\n",
    "Y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|score|                   X|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    1|(113463,[0,1,7,8,...|[-421.38956913796...|[0.00145588742341...|       1.0|\n",
      "|    1|(113463,[3,17,18,...|[-265.59445234650...|[0.81795169456594...|       0.0|\n",
      "|    1|(113463,[0,1,2,4,...|[-1093.5794889329...|[2.69468657757508...|       1.0|\n",
      "|    1|(113463,[4,23,45,...|[-81.546492754511...|[0.70894833793054...|       0.0|\n",
      "|    1|(113463,[0,15,22,...|[-183.16090056105...|[0.40769953415888...|       1.0|\n",
      "|    1|(113463,[0,9,139,...|[-87.038373058332...|[0.00214170430029...|       1.0|\n",
      "|    1|(113463,[2,12,15,...|[-111.98180698004...|[0.01561747942132...|       1.0|\n",
      "|    1|(113463,[0,1,8,15...|[-274.99054237735...|[3.76934719208345...|       1.0|\n",
      "|    1|(113463,[0,1,6,21...|[-164.37811017222...|[4.90553171319196...|       1.0|\n",
      "|    1|(113463,[0,21,46,...|[-106.93708400064...|[0.01252320023207...|       1.0|\n",
      "|    1|(113463,[0,4,6,15...|[-231.68216661992...|[1.60483486980395...|       1.0|\n",
      "|    1|(113463,[9,21,58,...|[-138.49322599138...|[7.77817835105874...|       1.0|\n",
      "|    1|(113463,[0,4,31,3...|[-206.77704429277...|[0.97166821093811...|       0.0|\n",
      "|    1|(113463,[0,4,15,4...|[-105.29681162743...|[0.04867918964810...|       1.0|\n",
      "|    1|(113463,[0,9,20,2...|[-191.22725612444...|[6.84828826449862...|       1.0|\n",
      "|    1|(113463,[0,1,7,8,...|[-320.53167736357...|[0.01568019831671...|       1.0|\n",
      "|    1|(113463,[13,19,27...|[-396.70381044226...|[0.00192176916059...|       1.0|\n",
      "|    1|(113463,[0,1,2,4,...|[-1067.1161906251...|[3.15673382095601...|       1.0|\n",
      "|    1|(113463,[46,61,71...|[-116.89549027868...|[0.99198897324053...|       0.0|\n",
      "|    1|(113463,[4,30,39,...|[-327.59368196224...|[9.48400209727753...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "tp :  0.46122 - fp :  0.03338 \n",
      "fn :  0.03878 - tn :  0.46662\n",
      "Accuracy :  0.92784 \n",
      "Precision :  0.9325111200970481 \n",
      "Specificity :  0.93324 \n",
      "Recall :  0.92244 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y.show()\n",
    "tp = Y.select('score', 'prediction').where((Y.score == 1)&(Y.prediction == 1)).count()/Y.count()\n",
    "tn = Y.select('score', 'prediction').where((Y.score == 0)&(Y.prediction == 0)).count()/Y.count()\n",
    "fp = Y.select('score', 'prediction').where((Y.score == 0)&(Y.prediction == 1)).count()/Y.count()\n",
    "fn = Y.select('score', 'prediction').where((Y.score == 1)&(Y.prediction == 0)).count()/Y.count()\n",
    "\n",
    "\n",
    "print('tp : ', tp, '- fp : ', fp, '\\nfn : ', fn, '- tn : ', tn)\n",
    "print('Accuracy : ', (tp+tn)/(tp+tn+fn+fp), '\\nPrecision : ', tp/(tp+fp), '\\nSpecificity : ', tn/(tn+fp), '\\nRecall : ', tp/(tp+fn), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp :  0.44268802822913406 - fp :  0.05729774337668251 \n",
      "fn :  0.06000113827153467 - tn :  0.4400130901226488\n",
      "Accuracy :  0.8827011183517829 \n",
      "Precision :  0.8854012521343199 \n",
      "Specificity :  0.8847848477912565 \n",
      "Recall :  0.8806396829889612 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split train / test\n",
    "training, test = X2.randomSplit([.8, .2])\n",
    "\n",
    "model2 = NB.fit(training)\n",
    "Y = model2.transform(test)\n",
    "\n",
    "tp = Y.select('score', 'prediction').where((Y.score == 1)&(Y.prediction == 1)).count()/Y.count()\n",
    "tn = Y.select('score', 'prediction').where((Y.score == 0)&(Y.prediction == 0)).count()/Y.count()\n",
    "fp = Y.select('score', 'prediction').where((Y.score == 0)&(Y.prediction == 1)).count()/Y.count()\n",
    "fn = Y.select('score', 'prediction').where((Y.score == 1)&(Y.prediction == 0)).count()/Y.count()\n",
    "\n",
    "\n",
    "print('tp : ', tp, '- fp : ', fp, '\\nfn : ', fn, '- tn : ', tn)\n",
    "print('Accuracy : ', (tp+tn)/(tp+tn+fn+fp), '\\nPrecision : ', tp/(tp+fp), '\\nSpecificity : ', tn/(tn+fp), '\\nRecall : ', tp/(tp+fn), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_data = loadData(['./Data/balanced_stemmed_amazon_350k.txt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|score|             comment|\n",
      "+-----+--------------------+\n",
      "|    5|It totally change...|\n",
      "|    2|Interesting Grish...|\n",
      "+-----+--------------------+\n",
      "\n",
      "None\n",
      "+-----+--------------------+--------------------+\n",
      "|score|             comment|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|    5|It totally change...|[it, totally, cha...|\n",
      "|    2|Interesting Grish...|[interesting, gri...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n",
      "None\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|score|             comment|               words|                   X|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    5|It totally change...|[it, totally, cha...|(102,[0,1,2,3,4,5...|\n",
      "|    2|Interesting Grish...|[interesting, gri...|(102,[0,2,3,5,7,8...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "\n",
      "None\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|score|             comment|               words|                   X|            features|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|    5|It totally change...|[it, totally, cha...|(102,[0,1,2,3,4,5...|(102,[0,1,2,3,4,5...|\n",
      "|    2|Interesting Grish...|[interesting, gri...|(102,[0,2,3,5,7,8...|(102,[0,2,3,5,7,8...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Quelques essais...\n",
    "file = sc.textFile('./Data/data_test.txt')\n",
    "\n",
    "data = file.map(lambda line: line.split(\"\\t\")).toDF()\n",
    "data = data.withColumnRenamed('_1', 'score') \n",
    "data = data.withColumn('score', data['score'].cast(IntegerType()))\n",
    "data = data.withColumnRenamed('_2', 'comment')\n",
    "\n",
    "print(data.show())\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(inputCol = \"comment\", outputCol = \"words\")\n",
    "data = tokenizer.transform(data)\n",
    "\n",
    "print(data.show())\n",
    "\n",
    "# Countvectorizer\n",
    "cv = CountVectorizer(inputCol = 'words', outputCol = 'X')\n",
    "model = cv.fit(data)\n",
    "data = model.transform(data)\n",
    "\n",
    "print(data.show())\n",
    "\n",
    "# TIDIDF\n",
    "idf = IDF(inputCol=\"X\", outputCol=\"features\")\n",
    "idfModel = idf.fit(data)\n",
    "data = idfModel.transform(data)\n",
    "\n",
    "print(data.show())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
